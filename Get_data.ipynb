{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to download data\n",
    "\n",
    "This notebook imports data for COVID related analysis from a number of online sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to import a few useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandasdmx import Request \n",
    "import eurostat\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have all packages. If not, type \"pip install --namepackage--\" in the console or in the terminal. We can now start to get the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to get the downloaded data in empty lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data From [World Population Prospects](https://population.un.org/wpp/Download/Standard/CSV/) and [Johns Hopkins](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series)\n",
    "\n",
    "John Hopkins provides daily data on **confirmed cases**, **deaths** and **recovered** for many countries in the world. Data can be freely accessed through GitHub. We can also get data from the UN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "def data_JH(url, container):\n",
    "    ind = 0\n",
    "    for i in url:\n",
    "        if ind <= len(url):\n",
    "            container.append([url[ind][0],pd.read_csv(url[ind][1], index_col = 0, parse_dates = [0])])\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare data to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_WPP = [['WPP_tot_pop', 'https://population.un.org/wpp/Download/Files/1_Indicators%20(Standard)/CSV_FILES/WPP2019_TotalPopulationBySex.csv'],\n",
    "          ['WPP_pop_age_sec', 'https://population.un.org/wpp/Download/Files/1_Indicators%20(Standard)/CSV_FILES/WPP2019_PopulationByAgeSex_Medium.csv'],\n",
    "          ['WPP_fertility', 'https://population.un.org/wpp/Download/Files/1_Indicators%20(Standard)/CSV_FILES/WPP2019_Fertility_by_Age.csv']]\n",
    "\n",
    "url_JH = [['JH_confirmed', 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'],\n",
    "            ['JH_death', 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'],\n",
    "            ['JH_recovered', 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data From [Eurostat](https://ec.europa.eu/eurostat/web/population-demography-migration-projections/data/database)\n",
    "\n",
    "The library Eurostat allows to get demographics data in one line of code. We download data about population as well as national accounts. Data need to be cleaned for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Eurostat(url, container):\n",
    "    ind = 0\n",
    "    for i in url:\n",
    "        if ind <= len(url):\n",
    "            container.append([url[ind][0], eurostat.get_data_df(url[ind][1])])\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the variables according to their codes on eurostat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eurostat_code = [['EU_pop', 'demo_r_gind3'], ['EU_gdp', 'nama_10_gdp'], ['EU_cons', 'nama_10_fcs'], ['EU_trade', 'nama_10_exi'], ['EU_short_rate', 'irt_st_a'],\n",
    "                ['EU_long_rate', 'irt_lt_gby10_a'], ['EU_unemp', 'une_rt_a'], ['EU_inv', 'nama_10_an6']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data From [Oxford COVID19 Government Response Tracker](https://www.bsg.ox.ac.uk/research/research-projects/oxford-covid-19-government-response-tracker)\n",
    "\n",
    "This dataset records a number of different measures that governments are taking to face the COVID19 outbreak around the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Ox(url, container):\n",
    "    ind = 0\n",
    "    for i in url:\n",
    "        if ind <= len(url):\n",
    "            container.append([url[ind][0],pd.read_excel(url[ind][1], index_col = 0, parse_dates = [0])])\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_Ox = [['OX_govt_responses', 'https://www.bsg.ox.ac.uk/sites/default/files/OxCGRT_Download_latest_data.xlsx']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data From [Sciensano - Belgium](https://epistat.wiv-isp.be/covid/)\n",
    "\n",
    "This dataset contains detailed information for Belgium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Belgium(url, container):\n",
    "    ind = 0\n",
    "    for i in url:\n",
    "        if ind <= len(url):\n",
    "            container.append([url[ind][0],pd.read_csv(url[ind][1], index_col = 0, parse_dates = [0], encoding = \"ISO-8859-1\")])\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_Belgium = [['Confirmed_cases_by_date_age_sex_and_province', 'https://epistat.sciensano.be/Data/COVID19BE_CASES_AGESEX.csv'],\n",
    "               ['Confirmed_cases_by_date_and_municipality', 'https://epistat.sciensano.be/Data/COVID19BE_CASES_MUNI.csv'],\n",
    "               ['Cumulative_number_of_confirmed_cases_by_municipality', 'https://epistat.sciensano.be/Data/COVID19BE_CASES_MUNI_CUM.csv'],\n",
    "               ['Hospitalisations_by_date_and_provinces', 'https://epistat.sciensano.be/Data/COVID19BE_HOSP.csv'],\n",
    "               ['Mortality_by_date_age_sex_and_province', 'https://epistat.sciensano.be/Data/COVID19BE_MORT.csv'],\n",
    "               ['Total_number_of_tests_performed_by_date', 'https://epistat.sciensano.be/Data/COVID19BE_tests.csv']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "We can now download all the data. To this end, we create empty containers and run the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "JH  = []\n",
    "WPP = []\n",
    "EU  = []\n",
    "OX  = []\n",
    "BE  = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers = 5) as e:\n",
    "    e.submit(data_JH(url_JH, JH))\n",
    "    e.submit(data_JH(url_WPP, WPP))\n",
    "    e.submit(data_Eurostat(Eurostat_code, EU))\n",
    "    e.submit(data_Ox(url_Ox, OX))\n",
    "    e.submit(data_Belgium(url_Belgium, BE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "This section is dedicated to do some preliminary data cleaning. First, we reshape JH data from wide to long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_JH(JH,JH_reshaped):\n",
    "    \n",
    "    for j in range(len(JH)):\n",
    "    \n",
    "        # Get and clean an entry of the JH list\n",
    "        tmp = pd.DataFrame(JH[j][1])\n",
    "        tmp = tmp.drop(['Lat', 'Long'], axis=1)\n",
    "\n",
    "        # Rename columns\n",
    "        tmp.columns = tmp.columns.str.replace('/','')\n",
    "        new_names = [(i,'Date' + i) for i in tmp.iloc[:, 1:].columns.values]\n",
    "        tmp.rename(columns = dict(new_names), inplace=True)\n",
    "\n",
    "        # Rename rows\n",
    "        tmp.index = pd.Series(tmp.index).replace(np.nan, 'Unique')\n",
    "\n",
    "        # Create a new ID = row name + first column\n",
    "        tmp['idx'] = tmp.index\n",
    "        tmp = tmp.set_index(['CountryRegion', 'idx'])\n",
    "        tmp['idx'] = tmp.index\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "\n",
    "        # Reshape wide to long\n",
    "        tmp = pd.wide_to_long(tmp, [\"Date\"], i=\"idx\", j=\"date\")\n",
    "        tmp = tmp.rename(columns = {'Date':'occurrences'})\n",
    "\n",
    "        # Clean index\n",
    "        idx = []\n",
    "        cou = []\n",
    "        reg = []\n",
    "        date = []\n",
    "        for k in range(len(tmp.index)):\n",
    "            idx.append(list(tmp.index[k])[0])\n",
    "            date.append(list(tmp.index[k])[1])\n",
    "        \n",
    "        # Get country and region identifier\n",
    "        for i in range(len(idx)):\n",
    "            cou.append(idx[i][0])\n",
    "            reg.append(idx[i][1])\n",
    "            \n",
    "        # Finalize dataset\n",
    "        tmp['country'] = cou  \n",
    "        tmp['region'] = reg  \n",
    "        tmp['date'] = [str(i)+'20' for i in date]\n",
    "        tmp['date'] = pd.to_datetime(tmp['date'], format='%m%d%Y', errors='coerce')\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        tmp = tmp[[\"country\", \"region\", \"date\", \"occurrences\"]]\n",
    "\n",
    "        # Store output in a new list\n",
    "        JH_reshaped.append([JH[j][0], tmp])\n",
    "        \n",
    "    #Return\n",
    "    return(JH_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "JH_reshaped = []\n",
    "JH_reshaped = reshape_JH(JH,JH_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all data\n",
    "\n",
    "Run the lines below **only** if you need to save data locally. The default path of the function is your current working directory. If another path is specified, the function will create the folders in that path if they do not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(path = os.getcwd(), JH_data = True, WPP_data = True, EU_data = True, Ox_data = True, BE_data = True):\n",
    "    os.makedirs(path, exist_ok = True)\n",
    "    if JH_data:\n",
    "        ind = 0\n",
    "        for i in JH_reshaped:\n",
    "            JH_reshaped[ind][1].to_csv(path + JH_reshaped[ind][0] + '.csv', index = False)\n",
    "            ind += 1\n",
    "    if WPP_data:\n",
    "        ind = 0\n",
    "        for i in WPP:\n",
    "            WPP[ind][1].to_csv(path + WPP[ind][0] + '.csv', index = False)\n",
    "            ind += 1\n",
    "    if EU_data:\n",
    "        ind = 0\n",
    "        for i in EU:\n",
    "            EU[ind][1].to_csv(path + EU[ind][0] + '.csv', index = False)\n",
    "            ind += 1\n",
    "    if Ox_data:\n",
    "        ind = 0\n",
    "        for i in OX:\n",
    "            OX[ind][1].to_csv(path + OX[ind][0] + '.csv', index = False)\n",
    "            ind += 1\n",
    "    if BE_data:\n",
    "        ind = 0\n",
    "        for i in BE:\n",
    "            BE[ind][1].to_csv(path + BE[ind][0] + '.csv', index = False)\n",
    "            ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data in a folder called *files* inside your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2354.8951001167297\n"
     ]
    }
   ],
   "source": [
    "store_data(os.getcwd() + \"/files/\")\n",
    "end_time = time.time()\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
